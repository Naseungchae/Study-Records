{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dense Layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOa/gCWxTRuNr1cxS+/XG9o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naseungchae/Study-Records/blob/main/Dense_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense layer"
      ],
      "metadata": {
        "id": "yYiJuvL2oDsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brBioHJsbxIR",
        "outputId": "6ee8a24e-5328-4720-8a9b-22b160414558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "input : [[ 0.22468439 -0.02518503  0.40026894 -0.5262036   1.7936236  -1.0527855\n",
            "  -1.9100151  -0.35860032  0.47279286 -0.26644725]]\n",
            "input shape : (1, 10)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "output : [[0.57310957 0.3625689  0.46520996]]\n",
            "output shape : (1, 3)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "weight : [[ 0.548908   -0.29520276 -0.16253799]\n",
            " [ 0.4742838   0.45995498 -0.6745634 ]\n",
            " [-0.3401522   0.13121623 -0.20248717]\n",
            " [-0.20929587  0.00887841 -0.17741466]\n",
            " [ 0.44852638 -0.30910316 -0.12785524]\n",
            " [ 0.22438955 -0.25018886  0.20672423]\n",
            " [ 0.0923934   0.11958325 -0.33657208]\n",
            " [ 0.39221513 -0.22034183  0.22521693]\n",
            " [ 0.26597285 -0.4190487  -0.5683901 ]\n",
            " [ 0.629388   -0.39168665 -0.08044672]]\n",
            "Weight shape : (10, 3)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "bias : [0. 0. 0.]\n",
            "bias shape : (3,)\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# input\n",
        "N , n_feature = 1, 10 # 1행 10열\n",
        "x = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "# Dense layer\n",
        "n_nueron = 3\n",
        "dense = Dense(units=n_nueron, activation='sigmoid') # 3개의 뉴런과 activation function으로 sigmoid를 갖는 dense layer\n",
        "# 해당 Dense layer에서 만들어지는 weight matrix의 shape은 10행 3열\n",
        "# 해당 Dense layer에서 만들어지는 bias vector의 shape은 row vector\n",
        "\n",
        "# output(activation value)\n",
        "a = dense(x) # 1행 3열\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "# 결과확인\n",
        "print('-'*100)\n",
        "print(f'input : {x}\\ninput shape : {x.shape}')\n",
        "print('-'*100)\n",
        "print(f'output : {a}\\noutput shape : {a.shape}')\n",
        "print('-'*100)\n",
        "print(f'weight : {W}\\nWeight shape : {W.shape}')\n",
        "print('-'*100)\n",
        "print(f'bias : {B}\\nbias shape : {B.shape}')\n",
        "print('-'*100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import exp\n",
        "from tensorflow.linalg import matmul\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# input\n",
        "N , n_feature = 5, 10\n",
        "x = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "# Dense layer\n",
        "n_nueron = 3\n",
        "dense = Dense(units=n_nueron, activation='sigmoid')\n",
        "\n",
        "# output(activation value)\n",
        "a_tf = dense(x)\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "# self_1\n",
        "z = matmul(x, W) + B # affine \n",
        "a_self = 1 / (1+exp(-z)) # activation\n",
        "\n",
        "# self_2 with numpy dot product\n",
        "output = np.zeros(shape=(N, n_nueron))\n",
        "\n",
        "for i in range(N):\n",
        "  x_index = x[i]\n",
        "  for k in range(n_nueron):\n",
        "    weight, bias = W[:,k], B[k]\n",
        "    z = tf.reduce_sum(x_index * weight) + bias\n",
        "    a = 1 / (1+np.exp(-z))\n",
        "    output[i, k] = a\n",
        "\n",
        "print(f'tensorflow output : {a_tf}\\ntensorflow output shape : {a_tf.shape}')\n",
        "print('-'*60)\n",
        "print(f'self_1 output : {a_self}\\nself_1 output shape : {a_self.shape}')\n",
        "print('-'*60)\n",
        "print(f'self_2 output : {output}\\nself_2 output shape : {output.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM091ee0e10C",
        "outputId": "3f43aea3-46a1-49d8-b688-56f037820a11"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow output : [[0.8583145  0.04846495 0.54198635]\n",
            " [0.36350334 0.07085541 0.23354122]\n",
            " [0.57156324 0.7611129  0.28974938]\n",
            " [0.34878314 0.4794724  0.85424125]\n",
            " [0.3304338  0.5701592  0.82671916]]\n",
            "tensorflow output shape : (5, 3)\n",
            "------------------------------------------------------------\n",
            "self_1 output : [[0.8583145  0.04846497 0.54198635]\n",
            " [0.36350334 0.07085543 0.23354122]\n",
            " [0.57156324 0.76111287 0.28974938]\n",
            " [0.34878314 0.47947243 0.85424125]\n",
            " [0.3304338  0.57015926 0.8267191 ]]\n",
            "self_1 output shape : (5, 3)\n",
            "------------------------------------------------------------\n",
            "self_2 output : [[0.85831451 0.04846496 0.54198631]\n",
            " [0.36350337 0.07085543 0.23354121]\n",
            " [0.57156329 0.76111289 0.28974938]\n",
            " [0.34878312 0.47947238 0.85424126]\n",
            " [0.33043375 0.57015925 0.82671915]]\n",
            "self_2 output shape : (5, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense layer 쌓기"
      ],
      "metadata": {
        "id": "5LuSq3g9n_Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# input\n",
        "N, n_feature = 5, 6\n",
        "x = tf.random.normal(shape=(N, n_feature)) #5행6열\n",
        "\n",
        "# dense layer\n",
        "n_nuerons = [5, 3]\n",
        "\n",
        "dense_1 = Dense(units=n_nuerons[0], activation='sigmoid') # 5개의 뉴런의 수를 갖는 dense layer\n",
        "dense_2 = Dense(units=n_nuerons[1], activation='sigmoid') # 3개의 뉴런의 수를 갖는 dense layer\n",
        "\n",
        "# output\n",
        "a1 = dense_1(x) # 5행5열\n",
        "a2 = dense_2(a1) # 5행3열\n",
        "\n",
        "# params\n",
        "W1, B1 = dense_1.get_weights()\n",
        "W2, B2 = dense_2.get_weights()\n",
        "\n",
        "# shape 확인\n",
        "print(f'input shape : {x.shape}')\n",
        "print('-'*50)\n",
        "print(f'a1 shape : {a1.shape}')\n",
        "print(f'weight shape : {W1.shape}\\nbias shape : {B1.shape}')\n",
        "print('-'*50)\n",
        "print(f'a2 shape : {a2.shape}')\n",
        "print(f'weight shape : {W2.shape}\\nbias shape : {B2.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQE1oLmHoB1O",
        "outputId": "36ee371e-d968-455d-f3ac-f326dd82369f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape : (5, 6)\n",
            "--------------------------------------------------\n",
            "a1 shape : (5, 5)\n",
            "weight shape : (6, 5)\n",
            "bias shape : (5,)\n",
            "--------------------------------------------------\n",
            "a2 shape : (5, 3)\n",
            "weight shape : (5, 3)\n",
            "bias shape : (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## for문으로 Dense layer 효율적으로 쌓기"
      ],
      "metadata": {
        "id": "KgrU4uFxsbGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# input\n",
        "N, n_feature = 5, 6\n",
        "x = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "# dense layer\n",
        "n_nuerons = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "dense_layers = []\n",
        "\n",
        "for n in n_nuerons:\n",
        "  dense = Dense(units=n, activation='relu')\n",
        "  dense_layers.append(dense)\n",
        "\n",
        "for index, dense in enumerate(dense_layers):\n",
        "  x = dense(x) # foward propagation\n",
        "  print('dense layer index :', index)\n",
        "  print(f'dense layer shape : {x.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-hMuna6sfMu",
        "outputId": "5c2a2b7c-7047-474f-9a27-c56ad4c176ed"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dense layer index : 0\n",
            "dense layer shape : (5, 10)\n",
            "dense layer index : 1\n",
            "dense layer shape : (5, 20)\n",
            "dense layer index : 2\n",
            "dense layer shape : (5, 30)\n",
            "dense layer index : 3\n",
            "dense layer shape : (5, 40)\n",
            "dense layer index : 4\n",
            "dense layer shape : (5, 50)\n",
            "dense layer index : 5\n",
            "dense layer shape : (5, 60)\n",
            "dense layer index : 6\n",
            "dense layer shape : (5, 70)\n",
            "dense layer index : 7\n",
            "dense layer shape : (5, 80)\n",
            "dense layer index : 8\n",
            "dense layer shape : (5, 90)\n",
            "dense layer index : 9\n",
            "dense layer shape : (5, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import exp\n",
        "from tensorflow.linalg import matmul\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "X_copy = tf.identity(X)\n",
        "\n",
        "# tensorflow\n",
        "n_nuerons = [3, 4, 5]\n",
        "dense_layers = []\n",
        "\n",
        "for n in n_nuerons:\n",
        "  dense = Dense(units=n, activation='sigmoid')\n",
        "  dense_layers.append(dense)\n",
        "\n",
        "weight, bias = [], []\n",
        "for index, dense in enumerate(dense_layers):\n",
        "  X = dense(X)\n",
        "  W, B = dense.get_weights()\n",
        "\n",
        "  weight.append(W)\n",
        "  bias.append(B)\n",
        "\n",
        "print(X) # output\n",
        "print('-' * 100)\n",
        "\n",
        "# self\n",
        "for index in range(len(n_nuerons)):\n",
        "  w, b = weight[index], bias[index]\n",
        "  X_copy = matmul(X_copy, w) + b\n",
        "  X_copy = 1/(1+exp(-X_copy))\n",
        "\n",
        "print(X_copy) # output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIIr23sUszjR",
        "outputId": "ce3cd295-1505-4a47-e810-fb387efea4ef"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.56290853 0.7054432  0.41389215 0.37710518 0.480882  ]\n",
            " [0.5604748  0.6963535  0.4159508  0.3790667  0.4812168 ]\n",
            " [0.5560808  0.69471127 0.41281018 0.38048592 0.4817238 ]\n",
            " [0.5519472  0.7069597  0.4016587  0.37331596 0.47684398]], shape=(4, 5), dtype=float32)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "tf.Tensor(\n",
            "[[0.56290853 0.7054432  0.41389212 0.37710515 0.48088202]\n",
            " [0.5604749  0.6963535  0.4159508  0.3790667  0.48121682]\n",
            " [0.5560808  0.69471127 0.41281018 0.38048592 0.48172373]\n",
            " [0.5519472  0.7069598  0.4016587  0.37331596 0.47684392]], shape=(4, 5), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}