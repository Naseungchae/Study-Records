{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "466479ed",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "> **classifiaction**  \n",
    "> : 입력 데이터를 미리 정의된 여러개의 클래스 중 하나로 예측하는 것\n",
    ">> **binary classification**(=이진 분류)  \n",
    ">> **multi-class classification**(=다중 분류)\n",
    "\n",
    "> **regression**  \n",
    "> : 연속적인 숫자를 예측하는 것\n",
    "\n",
    "## Supervised Learning Algorithm\n",
    "\n",
    "> - **Linear Regression** : 선형 회귀\n",
    "> - **Logistic Regression** : 로지스틱 회귀\n",
    "> - **Support Vector Machine** : 서포트 벡터 머신 \n",
    "> - **K-Nearest Neighbor** : k-최근접 이웃\n",
    "> - **Decision Tree** : 의사결정 나무\n",
    "> - **Ensemble** : 앙상블\n",
    "> - **Neural Networks** : 신경망\n",
    "\n",
    "---\n",
    "\n",
    "# Unsupervised Learning\n",
    "\n",
    ": 원하는 출력값 없이 입력 데이터를 사용하여 구조나 패턴을 찾는것이 목표\n",
    "\n",
    "> **Clustering** : 공간상에서 서로 가깝고 유사한 데이터를 클러스터로 그룹화\n",
    "\n",
    "> **Dimensionality Reduction**(=차원 축소) : 고차원의 데이터를 최대한 데이터의 손실 없이 데이터를 축소시키는 방법\n",
    "\n",
    "> **Association Rules**(=연관 규칙) : 데이터의 트성 간 연관성이 있는 규칙을 찾는 방법\n",
    "\n",
    "## Unsupervised Learning Algorithm\n",
    "\n",
    "> **Clustering**\n",
    "> - **K-Means** : k-평균 군집분석\n",
    "> - **DBSCAN**\n",
    "> - **Hierarchical Cluster Analysis** : 계층적 군집 분석\n",
    "> - **Outlier Detection** : 이상치 탐지\n",
    "> - **Novelty Detection** : 특이값 탐지\n",
    "\n",
    "> **Dimensionality Reduction**\n",
    "> - **Principal Component Analysis** : 주성분 분석\n",
    "> - **Kernel PCA**\n",
    "> - **t-SNE**\n",
    "\n",
    "> **Association Rules**\n",
    "> - **Apriori**\n",
    "> - **Eclat**\n",
    "\n",
    "---\n",
    "\n",
    "# Semi-supervised Learning\n",
    "\n",
    ": 레이블이 존재하는 것과 존재하지 않는 것이 혼합된 상태의 학습으로  \n",
    "Supervised_Learning Algorithm과 Unsupervised-Learning Algorithm의 조합으로 구성된다.\n",
    "\n",
    "---\n",
    "\n",
    "# Reinforcement Learning\n",
    "\n",
    ": 레이블의 유무에 상관없이 피드백기반의 학습방식을 사용한다.  \n",
    "(=에이전트가 동적 환경을 관찰하고 행동을 실행하여 피드백을 받아 자동으로 학습하여 성능을 향상시키는 방식)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37847f06",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "\n",
    ": 다양한 머신러닝 알고리즘이 구현되어 있는 파이썬 라이브러리\n",
    "\n",
    "> **Modules**\n",
    "> - **sklearn.preprocessing** : 데이터 전처리 기능 제공\n",
    "> - **sklearn.feature_selection** : 특징(=feature)을 선택할 수 있는 기능 제공\n",
    "> - **sklearn.feature_extraction** : 특징(=feature) 추출에 사용\n",
    "> - **sklearn.decomposition** : 차원 축소 관련 알고리즘 지원\n",
    "> - **sklearn.model_selection** : 교차 검증을 위해 데이터를 학습/테스트용으로 분리, 최적 파라미터를 추출하는 API제공\n",
    "> - **sklearn.metrics** : 분류, 회귀, 클러스터링, Pairwise에 대한 성능 측정 방법을 제공\n",
    "> - **sklearn.pipeline** : 특징 처리 등의 변환과 ML알고리즘 학습, 예측 등을 묶어서 실행할 수 있는 유틸리티 제공\n",
    "> - **sklearn.linear_model** : 선형모델 알고리즘을 제공\n",
    "> - **sklearn.svm** : SVM 알고리즘을 제공\n",
    "> - **sklearn.neighbors** : 최근접 이웃 알고리즘을 제공\n",
    "> - **sklearn.naive_bayes** : 나이브 베이즈 알고리즘 제공\n",
    "> - **sklearn.tree** : 의사결정나무 알고리즘 제공\n",
    "> - **sklearn.ensemble** : 앙상블 알고리즘 제공\n",
    "> - **sklearn.cluster** : 비지도 클러스터링 알고리즘 제공\n",
    "\n",
    "> **workflow**\n",
    "> 1. 적절한 estimator 클래스를 임포트해서 모델의 클래스 선택\n",
    "> 2. 클래스를 원하는 값으로 인스턴스화 해서 모델의 하이퍼파라미터를 선택\n",
    "> 3. 데이터를 특징 배열과 대상 벡터로 배치\n",
    "> 4. 모델 인스턴스의 **fit()**메서드를 호출해 모델을 데이터에 적합\n",
    "> 5. 모델을 새 데이터에 대해서 적용  \n",
    "    - supervised learning : **predict()** 메서드를 사용하여 알려지지 않은 데이터에 대한 레이블을 예측\n",
    "    - unsupervised learning : **transform()**이나 **predict()** 메서드를 사용하여 데이터의 속성을 변환하거나 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545f6d0",
   "metadata": {},
   "source": [
    "## sklearn.model_selection\n",
    "\n",
    "- **train_test_split()** : 학습/테스트 데이터 세트 분리  \n",
    "    *parameter = test_size, random_state*\n",
    "- **cross_val_score()** : 교차 검증    \n",
    "    *parameter = estimator, X, y, cv*\n",
    "- **GridSearchCV** :교차 검증과 최적의 하이퍼 파라미터 찾기  \n",
    "    *parameter* = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5370e6",
   "metadata": {},
   "source": [
    "## sklearn.preprocessing\n",
    "\n",
    "- 데이터의 feature scaling를 위한 대표적인 방법으로 **표준화**방식과 **정규화**방식을 사용한다.\n",
    "- sklearn에서는 개별 벡터의 크기를 맞추는 형태로 정규화를 진행한다.\n",
    "\n",
    "> **StandardScaler**, **MinMaxScaler**  \n",
    "    을 사용하면 한번에 해결되어지지만, return값이 numpy이기때문에 df로 변환하는 과정이 요구된다.\n",
    ">    \n",
    "> **StandardScaler** : 평균이 0과 표준편차가 1이 되도록 변환.  \n",
    ">  **MinMaxScaler** : 데이터 값을 0과 1사이의 범위 값으로 변환 (음수 존재 시, -1 ~ 1로 변환)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87362b55",
   "metadata": {},
   "source": [
    "## sklearn.metrics\n",
    "\n",
    "> **Accuracy(=정확도)**  \n",
    "> - 전체 예측 데이터 건수 중 예측 결과가 동일한 데이터 건수로 계산된다.\n",
    "> - 데이터의 분포가 균일하지 못한 경우에도 높게 측정이 될 수 있기 때문에 정확도만으로 판단할 수 없다.\n",
    "> - sklearn에서는 **accuracy_score**로 사용가능하다.\n",
    "\n",
    "> **Confusion Matrix(=오차 행렬)**\n",
    ">> - True Negative(TN) : 예측값을 Negative값 0으로 예측했고, 실제값도 Negative값 0\n",
    ">> - False Positive(FP) : 예측값을 Positive값 1으로 예측했지만, 실제값은 Negative값 0\n",
    ">> - False Negative(FN) : 예측값을  Negative값 0으로 예측했지만, 실제값은 Positive 1\n",
    ">> - True Positive(TP) : 예측값을 Positive값 1으로 예측했고, 실제값도 Positive값 1\n",
    "> - sklearn에서는 **confusion_matrix**로 사용가능하다.\n",
    "\n",
    "> **Precision(=정밀도)와 Recall(재현율)**\n",
    ">> - 정밀도 : TP / (FP + TP)\n",
    ">> - 재현율 : TP / (FN + TP)\n",
    ">> - 정확도 : TN + TP / TN + FP +FN +TP\n",
    ">> - 요류율 = FN + FP / TN + FP + FN + TP  \n",
    "> - sklearn에서는 **precision_score**와 **recall_score**로 사용 가능하다.\n",
    "\n",
    "> **F1 Score**\n",
    "> - 정밀도와 재현율을 결합한 지표로 어느 한쪽으로 치우치지 않을 때 높은 값을 갖는다.\n",
    "> - sklearn에서는 **f1_score**로 사용가능하다.\n",
    "\n",
    "> **ROC CURVE와 AUC**  \n",
    "> - ROC CURVE는 False Positive 비율이 변할 때 True Positive비율이 어떻게 변하는지를 나타내는 곡선이다.\n",
    ">>- True Positive 비율 : TP / FN + TP == 재현율\n",
    ">>- False Positive 비율 : FP / FP + TN\n",
    "> - AUC는 ROC곡선 밑의 면적을 계산한 값으로 1에 가까울수록 좋다.\n",
    "> - sklearn에서는 **roc_auc_score**로 사용 가능하다. (값)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Machine Learning",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.319px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
